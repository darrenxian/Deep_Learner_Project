{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Lambda, Flatten\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "from keras_vggface import utils\n",
    "from keras.preprocessing import image\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial import distance\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_vgg16.h5\n",
      "580075520/580070376 [==============================] - 17s 0us/step\n",
      "580083712/580070376 [==============================] - 17s 0us/step\n"
     ]
    }
   ],
   "source": [
    "def l2_norm(x):\n",
    "    #x2=tf.nn.l2_normalize(x,axis=None,epsilon=1e-12,name=None,dim=None)\n",
    "    x2=tf.nn.l2_normalize(x,dim=1)\n",
    "    return x2\n",
    "\n",
    "\n",
    "# CHOOSE AN ARCHITECTURE:  \n",
    "architecture = 'vgg'\n",
    "# architecture = 'resnet'\n",
    "\n",
    "\n",
    "dirpath = os.getcwd()\n",
    "\n",
    "# The images that we are using are already cropped, \n",
    "# so we don't need to detect face positions\n",
    "\n",
    "bbox_1 = [0,0,224,224]\n",
    "bbox_2 = [0,0,224,224]\n",
    "\n",
    "\n",
    "if architecture == 'vgg':\n",
    "    #baseline model with vgg:\n",
    "    vgg_model = VGGFace(model = 'vgg16')\n",
    "#                        CHANGE LAYER HERE  \\/\n",
    "    feature_layer = vgg_model.get_layer('fc7/relu').output\n",
    "    model = Model(vgg_model.input, feature_layer)\n",
    "    version = 1 \n",
    "\n",
    "\n",
    "elif architecture == 'resnet':\n",
    "    #baseline model with resnet:\n",
    "    resnet = VGGFace(model = 'resnet50')\n",
    "    \n",
    "#                   CHANGE LAYER HERE  \\/\n",
    "    last_layer = resnet.get_layer('avg_pool').output\n",
    "    feature_layer = Flatten(name='flatten')(last_layer)\n",
    "    model = Model(resnet.input, feature_layer)\n",
    "    version = 2   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create method to get distance between 2 images:\n",
    "Note: This code can return Cosine Similarity (1=Match) and Euclidean Distance (0=Match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RunModel(img_url_1,img_url_2):\n",
    "    # first image:\n",
    "#     img_url_1 = dirpath + img_url_1\n",
    "#     img_url_2 = dirpath + img_url_2\n",
    "    img_1 = cv2.imread(img_url_1)\n",
    "#     img_1 = img_1/255\n",
    "#     img_1 = img_1[bbox_1[1]:bbox_1[1]+bbox_1[3],bbox_1[0]:bbox_1[0]+bbox_1[2],:]\n",
    "#     img_1 = misc.imresize(img_1, (224, 224), interp='bilinear')\n",
    "    img_1 = image.img_to_array(img_1)\n",
    "    img_1 = np.expand_dims(img_1, axis=0)\n",
    "    img_1 = utils.preprocess_input(img_1, version=version) # version=1 for vgg16, version=2 for resnet50\n",
    "    predict_1 = model.predict(img_1) # predict with baseline model\n",
    "    baseline_features_1 = preprocessing.normalize(predict_1, norm='l2', axis=1, copy=True, return_norm=False)\n",
    "\n",
    "    # second image:\n",
    "    img_2 = cv2.imread(img_url_2)\n",
    "#     img_2 = img_2/255\n",
    "#     img_2 = img_2[bbox_2[1]:bbox_2[1]+bbox_2[3],bbox_2[0]:bbox_2[0]+bbox_2[2],:]\n",
    "#     img_2 = misc.imresize(img_2, (224, 224), interp='bilinear')\n",
    "    img_2 = image.img_to_array(img_2)\n",
    "    img_2 = np.expand_dims(img_2, axis=0)\n",
    "    img_2 = utils.preprocess_input(img_2, version=version) # version=1 for vgg16, version=2 for resnet50\n",
    "    predict_2 = model.predict(img_2) # predict with baseline model\n",
    "    baseline_features_2 = preprocessing.normalize(predict_2, norm='l2', axis=1, copy=True, return_norm=False)\n",
    "\n",
    "\n",
    "    # Calculate distances:\n",
    "    baseline_distance = distance.euclidean(baseline_features_1, baseline_features_2)\n",
    "    cosine_distance = cosine_similarity(baseline_features_1, baseline_features_2)\n",
    "    \n",
    "    return(cosine_distance,baseline_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir = os.listdir('C:/Users/Public/Documents/PNAS2018Images/CroppedDatabase/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir = list_dir[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D1_a.png',\n",
       " 'D1_b.png',\n",
       " 'D2_a.png',\n",
       " 'D2_b.png',\n",
       " 'D3_a.png',\n",
       " 'D3_b.png',\n",
       " 'D4_a.png',\n",
       " 'D4_b.png',\n",
       " 'D5_a.png',\n",
       " 'D5_b.png',\n",
       " 'D6_a.png',\n",
       " 'D6_b.png',\n",
       " 'D7_a.png',\n",
       " 'D7_b.png',\n",
       " 'D8_a.png',\n",
       " 'D8_b.png',\n",
       " 'S10_a.png',\n",
       " 'S10_b.png',\n",
       " 'S11_a.png',\n",
       " 'S11_b.png',\n",
       " 'S12_a.png',\n",
       " 'S12_b.png',\n",
       " 'S1_a.png',\n",
       " 'S1_b.png',\n",
       " 'S2_a.png',\n",
       " 'S2_b.png',\n",
       " 'S3_a.png',\n",
       " 'S3_b.png',\n",
       " 'S4_a.png',\n",
       " 'S4_b.png',\n",
       " 'S5_a.png',\n",
       " 'S5_b.png',\n",
       " 'S6_a.png',\n",
       " 'S6_b.png',\n",
       " 'S7_a.png',\n",
       " 'S7_b.png',\n",
       " 'S8_a.png',\n",
       " 'S8_b.png',\n",
       " 'S9_a.png',\n",
       " 'S9_b.png']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result=[]\n",
    "for i in range(0,40,2):\n",
    "    model_result.append(RunModel('C:/Users/Public/Documents/PNAS2018Images/CroppedDatabase/' + list_dir[i],'C:/Users/Public/Documents/PNAS2018Images/CroppedDatabase/' + list_dir[i+1])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2423360347747803\n",
      "1.0521906614303589\n",
      "1.231949806213379\n",
      "1.204210638999939\n",
      "1.1822668313980103\n",
      "1.252505898475647\n",
      "1.3348255157470703\n",
      "1.1929364204406738\n",
      "1.1784367561340332\n",
      "1.2603089809417725\n",
      "1.1280832290649414\n",
      "1.2525523900985718\n",
      "1.0974434614181519\n",
      "0.9841029644012451\n",
      "1.3473163843154907\n",
      "1.1835050582885742\n",
      "1.361786961555481\n",
      "1.1355843544006348\n",
      "1.2285377979278564\n",
      "1.1635668277740479\n"
     ]
    }
   ],
   "source": [
    "# Show the scores\n",
    "for i in range(len(model_result)):\n",
    "    print(model_result[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2423360347747803,\n",
       " 1.0521906614303589,\n",
       " 1.231949806213379,\n",
       " 1.204210638999939,\n",
       " 1.1822668313980103,\n",
       " 1.252505898475647,\n",
       " 1.3348255157470703,\n",
       " 1.1929364204406738,\n",
       " 1.1784367561340332,\n",
       " 1.2603089809417725,\n",
       " 1.1280832290649414,\n",
       " 1.2525523900985718,\n",
       " 1.0974434614181519,\n",
       " 0.9841029644012451,\n",
       " 1.3473163843154907,\n",
       " 1.1835050582885742,\n",
       " 1.361786961555481,\n",
       " 1.1355843544006348,\n",
       " 1.2285377979278564,\n",
       " 1.1635668277740479]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show square matrix:\n",
    "\n",
    "model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save matrix\n",
    "np.savetxt('Euclidean_Distances.csv',model_result,\n",
    "          delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "\n",
    "for i in range(8):\n",
    "    ground_truth.append('different') \n",
    "\n",
    "for i in range(12):\n",
    "    ground_truth.append('same')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,thresholds = sklearn.metrics.roc_curve(ground_truth,np.array(model_result),pos_label='different')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.08333333, 0.16666667, 0.16666667, 0.33333333,\n",
       "        0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "        0.91666667, 0.91666667, 1.        ]),\n",
       " array([0.   , 0.   , 0.   , 0.125, 0.125, 0.5  , 0.5  , 0.75 , 0.75 ,\n",
       "        0.875, 0.875, 1.   , 1.   ]),\n",
       " array([2.36178696, 1.36178696, 1.34731638, 1.33482552, 1.25255239,\n",
       "        1.23194981, 1.2285378 , 1.19293642, 1.18350506, 1.18226683,\n",
       "        1.09744346, 1.05219066, 0.98410296]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr,tpr,thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1653c475d90>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5729166666666667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
